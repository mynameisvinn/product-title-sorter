{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "problem: (1) for each item belonging to one of the four categories (cases, laptop, mp3, and cellphones), find its nearest neighbors; (2) cluster items.\n",
    "\n",
    "the following notebook shows a multi-step pipeline that (1) preprocesses (eg extracts named entity); (2) generates term document matrices; (3) organizes feature vectors via approximate nearest neighbor (ANN); and (4) clusters via k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 0: dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.decomposition import PCA\n",
    "from spacy.en import English\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251432713573</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360826556319</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181185253117</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271331653100</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111221678527</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  site category  \\\n",
       "0  251432713573     0      177   \n",
       "1  360826556319     0      177   \n",
       "2  181185253117     0      177   \n",
       "3  271331653100     0      177   \n",
       "4  111221678527     0      177   \n",
       "\n",
       "                                               title  \n",
       "0  LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...  \n",
       "1  HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...  \n",
       "2  Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...  \n",
       "3  HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...  \n",
       "4  CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table('data/laptops 177.txt', header = None)\n",
    "data.columns = ['id', 'site', 'category', 'title']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56638, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = data.ix[:1000]\n",
    "data_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: text preprocessing\n",
    "\n",
    "since we're generating a term document matrix from products-centric titles, lets focus on nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_nouns_from_title(title):\n",
    "    '''\n",
    "    function:\n",
    "    ---------\n",
    "    extract nouns from a product title. by doing so, we effectively fit tdm to the most\n",
    "    relevant aspects of the title string.\n",
    "    \n",
    "    parameter:\n",
    "    ----------\n",
    "    @title: str, refering to product title.\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    @title_nouns_only: str, referring to product title with nouns only. this output will be \n",
    "    used to fit a term document matrix.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        title = unicode(title)\n",
    "        parsedData = parser(title)\n",
    "        \n",
    "        # split product title into multiple sentences if necessary\n",
    "        for span in parsedData.sents:\n",
    "            sent = [parsedData[i] for i in range(span.start, span.end)]\n",
    "            break\n",
    "        \n",
    "        # collect tokens only if they are nouns\n",
    "        title_nouns_only = [token.orth_ for token in sent if token.pos_ == 'NOUN']\n",
    "        return \" \".join(title_nouns_only)\n",
    "    \n",
    "    except:\n",
    "        return title # certain char not recognized and cannot be recasted to unicode!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincenttang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# create new column by mapping extract_nouns_from_title() to titles\n",
    "\n",
    "data_2['title_clean'] = map(lambda x: extract_nouns_from_title(x), data_2['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: n-grams & tdm\n",
    "\n",
    "generate term document matrix of ngrams using \"clean\" titles. in this specific example, i'll extract unigrams, bigrams and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PRE-FITTED VECTORIZER IF IT EXISTS\n",
    "\n",
    "# vec = joblib.load('models/mp3/mp3_vec_v1.pkl')\n",
    "# tdm_sparse = vec.transform(data_2['title_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/laptops/laptops_vec_v1.pkl',\n",
       " 'models/laptops/laptops_vec_v1.pkl_01.npy',\n",
       " 'models/laptops/laptops_vec_v1.pkl_02.npy']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT NEW VECTORIZER\n",
    "\n",
    "vec = TfidfVectorizer(stop_words= 'english',ngram_range=(1,3),lowercase=True, max_features=1000)\n",
    "tdm_sparse = vec.fit_transform(data_2['title_clean'])\n",
    "joblib.dump(vec, 'models/laptops/laptops_vec_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check tdm features\n",
    "\n",
    "vec.get_feature_names()[1000:1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   990  991  992  993  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   994  995  996  997  998  999  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dense array for dimensionality reduction\n",
    "\n",
    "tdm_dense = tdm_sparse.toarray()\n",
    "tdm_dense_df = pd.DataFrame(tdm_dense)\n",
    "tdm_dense_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FIT PCA - should skip this step since ANN can search high dimensional vectors\n",
    "\n",
    "# reducer = PCA(n_components = 500)\n",
    "# tdm_reduced = reducer.fit_transform(tdm_dense)\n",
    "# joblib.dump(reducer, 'models/mp3/mp3_reducer_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD PRE-FITTED REDUCER\n",
    "\n",
    "# reducer = joblib.load('models/mp3/mp3_reducer_v1.pkl')\n",
    "# tdm_reduced = reducer.transform(tdm_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm_reduced_df = pd.DataFrame(tdm_dense_df)\n",
    "tdm_reduced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: extract named entities\n",
    "\n",
    "extracting named entities will resolve limitations of inverse weighting schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate parser from spacy.io (nltk didnt work well)\n",
    "\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_named_entities(sentence):\n",
    "    '''\n",
    "    function:\n",
    "    ---------\n",
    "    given a product title string, identify the named entity. a separate tdm will be fitted with\n",
    "    named entities.\n",
    "    \n",
    "    parameter:\n",
    "    ----------\n",
    "    @sentence: str, referring to product title string.\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    @named entity: str, referring to named entity in product title.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        sentence = unicode(sentence)\n",
    "        doc = parser(sentence)\n",
    "        return [chunk.orth_ for chunk in doc.noun_chunks][0]\n",
    "    \n",
    "    # catch instances where title string cannot be converted into unicode!\n",
    "    except:\n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincenttang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251432713573</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...</td>\n",
       "      <td>LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360826556319</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...</td>\n",
       "      <td>HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181185253117</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...</td>\n",
       "      <td>Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271331653100</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...</td>\n",
       "      <td>HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...</td>\n",
       "      <td>HDD,DVD-W,Win8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111221678527</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...</td>\n",
       "      <td>CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  site category  \\\n",
       "0  251432713573     0      177   \n",
       "1  360826556319     0      177   \n",
       "2  181185253117     0      177   \n",
       "3  271331653100     0      177   \n",
       "4  111221678527     0      177   \n",
       "\n",
       "                                               title  \\\n",
       "0  LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...   \n",
       "1  HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...   \n",
       "2  Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...   \n",
       "3  HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...   \n",
       "4  CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...   \n",
       "\n",
       "                                         title_clean           nouns  \n",
       "0  LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...              NA  \n",
       "1  HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...              NA  \n",
       "2  Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...              NA  \n",
       "3  HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...  HDD,DVD-W,Win8  \n",
       "4  CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...              NA  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column by mapping extract_named_entities() to titles\n",
    "\n",
    "data_2['nouns'] = map(lambda x: extract_named_entities(x), data_2['title'])\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/mp3/mp3_ne_vec_v1.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT NAMED ENTITY VECTORIZER\n",
    "\n",
    "ne_vec = CountVectorizer(stop_words= None,ngram_range=(2,3),lowercase=True, max_features=200)\n",
    "ne_tdm_sparse = ne_vec.fit_transform(data_2['nouns'])\n",
    "joblib.dump(ne_vec, 'models/mp3/mp3_ne_vec_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# USE PRE-FITTED VECTORIZER\n",
    "\n",
    "# ne_vec = joblib.load('models/mp3/mp3_ne_vec_v1.pkl')\n",
    "# ne_tdm_sparse = ne_vec.transform(data_2['nouns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tdm_dense = ne_tdm_sparse.toarray()\n",
    "ne_tdm_dense_df = pd.DataFrame(ne_tdm_dense)\n",
    "\n",
    "ne_tdm_dense_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FIT NEW PCA\n",
    "\n",
    "# ne_reducer = PCA(n_components = 500)\n",
    "#ne_tdm_reduced = ne_reducer.fit_transform(ne_tdm_dense)\n",
    "#joblib.dump(ne_reducer, 'models/laptops/laptops_ne_reducer_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD FITTED PCA\n",
    "# ne_reducer = joblib.load('models/mp3/mp3_reducer_v1.pkl')\n",
    "# ne_tdm_reduced = ne_reducer.transform(ne_tdm_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 200)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tdm_reduced_df = pd.DataFrame(ne_tdm_dense_df)\n",
    "ne_tdm_reduced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: merge dataframes\n",
    "\n",
    "in this section, i merge product tdm (with inverse weighting) with named entity tdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.concat([tdm_reduced_df, ne_tdm_reduced_df], axis = 1)\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6: instantiate ANN\n",
    "\n",
    "i use ANN to enforce structure on items. ANNs will reduce the search space for downstream nearest neighbor tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a: populate ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = AnnoyIndex(features_df.shape[1])\n",
    "\n",
    "# populate ANN with each item \n",
    "for i in range(len(features_df)):\n",
    "    \n",
    "    vector = features_df.ix[i].tolist()\n",
    "    ann.add_item(i, vector) \n",
    "    \n",
    "ann.build(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b: inspect top 10 nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_nearest_neighbors(query_idx):\n",
    "    '''\n",
    "    function:\n",
    "    ---------\n",
    "    given an item ID, print its 10 closest neighbors according to the pre-defined ANN.\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    @query_idx: int, representing the 12 digit item ID\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    row_idx = np.where(data['id'] == query_idx)[0][0] #  look up corresponding item ID\n",
    "    \n",
    "    neighbors = ann.get_nns_by_item(row_idx,11) # return 11 neighbors as the first one is a duplicate\n",
    "    \n",
    "    for n in neighbors:\n",
    "        print data_2['title'].ix[n], cosine_similarity(features_df.ix[row_idx], features_df.ix[n])[0][0]\n",
    "        print '-' * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/4GB RAM/160GB HD item# SKU 2089881 1.0\n",
      "--------------------------------------------------\n",
      "LENOVO THINKPAD T400/ CORE 2 DUO 2.40GHZ/4GB RAM/160GB HD item# SKU 2103911 0.71370073873\n",
      "--------------------------------------------------\n",
      "Dell Latitude E6400 Laptop 2.53ghz Core 2 Duo 4GB Ram 160GB HD DVD-RW Win 7 PRO 0.569046782221\n",
      "--------------------------------------------------\n",
      "PANASONIC TOUGHBOOK CF30/ WIFI/TOUCHSCREEN  / 3GB RAM/ 160GB HD/ WIN 8/  0.413448865023\n",
      "--------------------------------------------------\n",
      "Dell Latitude E4300 13.3\" Laptop Core 2 Duo P9600 2.53GHz 4GB 160GB *No Battery* 0.330585679128\n",
      "--------------------------------------------------\n",
      "IBM ThinkPad X60 12.1\" Core Duo 1.6GHz 1GB RAM 160GB HDD Tablet WiFi 0.267544149274\n",
      "--------------------------------------------------\n",
      "Lenovo ThinkPad T400 Intel Core2Duo T9400 1GB 2.53GHz 0.267201647908\n",
      "--------------------------------------------------\n",
      "IBM THINKPAD LENOVO T400 Core 2 DUO 2.53GHz 4GB 500GB 14.1\" DVD-RW WEBCAM 0.251476125454\n",
      "--------------------------------------------------\n",
      "CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB Ram 160GB HDD DVD/RW  Wi-Fi Ready 0.251285822796\n",
      "--------------------------------------------------\n",
      "Dell Vostro 200 Core 2 Duo E7200 2.53Ghz 4GB 250GB DVDRW Tower Computer 0.239732934268\n",
      "--------------------------------------------------\n",
      "Lenovo ThinkPad SL510 15.6\" Core 2 Duo 2.20GHz 4GB 320GB 2847 Win7 PRO Notebook  0.214292059577\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test case\n",
    "\n",
    "retrieve_nearest_neighbors(251432713573)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 7: store nearest neighbors to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each record, find and store its nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest_neighbors(row_id, num_neighbors):\n",
    "    \n",
    "    '''\n",
    "    function:\n",
    "    ---------\n",
    "    given an index id, return its 10 nearest neighbors. this version uses index id but\n",
    "    should be converted to accept item id. next time.\n",
    "    \n",
    "    returns a list of strings of index IDs. itll make it easier to construct a tdm of neighbors\n",
    "    for clustering purposes.\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    @row_id: int, referring to item's index id in the dataframe.\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    @neighbors: str list containing index IDs for nearest neighbors.\n",
    "    '''\n",
    "    neighbors_by_itemID = map(lambda x: rowID_to_itemID(x), ann.get_nns_by_item(row_id,num_neighbors))\n",
    "    \n",
    "    # convert to str and remove first element, which is the query item\n",
    "    neighbors = map(lambda x: str(x), neighbors_by_itemID) \n",
    "    \n",
    "    neighbors.pop(0) # remove the first element, which is the query item (duplicate)\n",
    "    \n",
    "    neighbors = ' '.join(neighbors)\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def rowID_to_itemID(row_id):\n",
    "    '''\n",
    "    helper function for converting dataframe index to item ID\n",
    "    '''\n",
    "    return data_2['id'][row_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincenttang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>nouns</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251432713573</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...</td>\n",
       "      <td>LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...</td>\n",
       "      <td>NA</td>\n",
       "      <td>121261643802 121261069573 301001430347 1411734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360826556319</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...</td>\n",
       "      <td>HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...</td>\n",
       "      <td>NA</td>\n",
       "      <td>151215670348 201024236281 111241032287 2513157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181185253117</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...</td>\n",
       "      <td>Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...</td>\n",
       "      <td>NA</td>\n",
       "      <td>301032497619 181144309508 191029299535 2713745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271331653100</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...</td>\n",
       "      <td>HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...</td>\n",
       "      <td>HDD,DVD-W,Win8</td>\n",
       "      <td>390740843954 400620260842 370987892664 3807681...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111221678527</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...</td>\n",
       "      <td>CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...</td>\n",
       "      <td>NA</td>\n",
       "      <td>121203685985 121261069573 301079281716 3006943...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  site category  \\\n",
       "0  251432713573     0      177   \n",
       "1  360826556319     0      177   \n",
       "2  181185253117     0      177   \n",
       "3  271331653100     0      177   \n",
       "4  111221678527     0      177   \n",
       "\n",
       "                                               title  \\\n",
       "0  LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...   \n",
       "1  HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...   \n",
       "2  Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...   \n",
       "3  HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...   \n",
       "4  CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...   \n",
       "\n",
       "                                         title_clean           nouns  \\\n",
       "0  LENOVO THINKPAD T500/CORE 2 DUO T9400/2.53GHZ/...              NA   \n",
       "1  HP Compaq 6715b Turion 64x2 1.8Ghz 512MB 15\" W...              NA   \n",
       "2  Lenovo ThinkPad Edge E430 3254-ACU Notebook PC...              NA   \n",
       "3  HP F0Q65UA 15.6\" LED Notebook,AMD A4-5000 1.5G...  HDD,DVD-W,Win8   \n",
       "4  CANDY PINK Dell Latitude D630 C2D 2.4GHz 4GB R...              NA   \n",
       "\n",
       "                                   nearest_neighbors  \n",
       "0  121261643802 121261069573 301001430347 1411734...  \n",
       "1  151215670348 201024236281 111241032287 2513157...  \n",
       "2  301032497619 181144309508 191029299535 2713745...  \n",
       "3  390740843954 400620260842 370987892664 3807681...  \n",
       "4  121203685985 121261069573 301079281716 3006943...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column called \"nearest neighbors\" by mapping find_nearest_neighbors() to index ID\n",
    "\n",
    "data_2['nearest_neighbors'] = map(lambda x: find_nearest_neighbors(x, 11), data_2.index)\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store data in csv format\n",
    "\n",
    "data_2['nearest_neighbors'].to_csv('output/laptops/laptops_neighbors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# step 8: cluster\n",
    "\n",
    "clustering was accomplished via kmeans. \n",
    "\n",
    "a tdm representing item's 10 nearest neighbors was generated. therefore, each item was represented by a 1000-dimensional vector, where each feature corresponded to an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors_vec = CountVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 977)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit tdm to 10 nearest neighbors\n",
    "\n",
    "neighbors_tdm_sparse = neighbors_vec.fit_transform(data_2['nearest_neighbors'])\n",
    "neighbors_tdm_dense = neighbors_tdm_sparse.toarray()\n",
    "neighbors_tdm_dense_df = pd.DataFrame(neighbors_tdm_dense)\n",
    "neighbors_tdm_dense_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=50, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(n_clusters=50, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(neighbors_tdm_dense_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = model.predict(neighbors_tdm_dense_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29                                  Compaq Presario 1900\n",
      "33     Compaq Presario F500 Laptop w/ Battery, AMD Se...\n",
      "121                COMPAQ PRESARIO MODEL 1700T  WORKING \n",
      "206    Compaq Presario CQ60-224NR Dual Core 2.16GHz/3...\n",
      "238    Compaq Presario V6120US 15.4\" Notebook Windows...\n",
      "420    Compaq Presario CQ56-219WM Windows 7 Home Prem...\n",
      "544    Compaq Presario V2000 CELERON 1.40GHZ 512MB NO...\n",
      "609    HP Compaq Presario CQ60-211 15.6\" Notebook - C...\n",
      "631                    Compaq Presario M2000 (For Parts)\n",
      "697    Compaq Presario CQ57-339WM Intel Celeron Proce...\n",
      "873    Compaq Presario X1000 Laptop *Boots to Bios* F...\n",
      "930    HP Compaq Presario F750US 15.4\" (160 GB, AMD A...\n",
      "942                      Compaq 12\" Presario 1245 Laptop\n",
      "984    COMPAQ PRESARIO C700/ INTEL PENTIUM DUAL/ 1.40...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# inspect clusters\n",
    "\n",
    "cluster_idx = 10\n",
    "\n",
    "selectors = np.where(categories == cluster_idx)\n",
    "\n",
    "for idx in selectors:\n",
    "    print data_2['title'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
